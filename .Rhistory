myData$grupo<-as.factor(km$cluster)
g1<- myData[myData$grupo==1,]
g2<- myData[myData$grupo==2,]
g1
summary(g1)
summary(g2)
library(foreign)#lectura archivos .sav
library(ggplot2)
library(dplyr)
library(plyr)
library(cluster)
library(fpc)
library(mclust)
library(e1071)#para cmeans
library(factoextra)
#IVETTE
dataset16 = read.spss(file.choose(), to.data.frame=TRUE)
dataset17 = read.spss(file.choose(), to.data.frame=TRUE)
myvars16 <- c("AGR_EDAD", "VIC_EDAD", "AGR_GURPET", "VIC_GRUPET", "AGRESORES_OTROS_TOTAL", "INST_DONDE_DENUNCIO", "DEPTO_MCPIO", "TOTAL_HIJOS", "OTRAS_VICTIMAS", "AGR_ALFAB", "AGR_TRABAJA", "HEC_DEPTOMCPIO")
newdata16 <- select(dataset16, one_of(myvars16))
newdata16
myvars17 <- c("AGR_EDAD", "VIC_EDAD", "AGR_GURPET", "VIC_GRUPET", "AGRESORES_OTROS_TOTAL", "INST_DONDE_DENUNCIO", "DEPTO_MCPIO", "TOTAL_HIJOS", "OTRAS_VICTIMAS", "AGR_ALFAB", "AGR_TRABAJA", "HEC_DEPTOMCPIO")
newdata17 <- select(dataset17, one_of(myvars17))
newdata17
datosP = merge(newdata16,newdata17, all.x=TRUE)
library(caret)
library(nnet)
library(RWeka)
library(neural)
library(dummies)
library(neuralnet)
library(e1071)
library(foreign)#lectura archivos .sav
library(caret)
library(e1071)
#IVETTE
#Test and train
set.seed(123)
porcentaje<-0.7
datosP$y<- as.numeric(datosP$Type)
datosP$y<- as.numeric(datosP$Type)
trainRowsNumber<-sample(1:nrow(datosP),70/100*nrow(datosP))
train<-datosP[trainRowsNumber,]
test<-datosP[-trainRowsNumber,]
corte <- sample(nrow(datosP),nrow(datosP)*porcentaje)
test = na.omit(test)
train = na.omit(train)
rownames(test) <- c()
rownames(train) <- c()
View(test)
#Plot the dataset
plot(train,pch=16)
#Linear regression
model <- lm(AGR_ALFAB ~ ., train)
#Plot the model using abline
abline(model)
train$AGR_ALFAB <- as.factor(train$AGR_ALFAB)
#M1
model_svm <- svm(AGR_ALFAB ~ . , train)
model_svm
pred <- predict(model_svm, test[,1:ncol(test)])
confusionMatrix(as.factor(test$AGR_ALFAB),pred)
library(foreign)#lectura archivos .sav
library(caret)
library(e1071)
library(nnet)
library(RWeka)
library(neural)
library(dummies)
library(neuralnet)
library(MASS);
library(neuralnet)
library(ggplot2)
install.packages("nnet")
install.packages("nnet")
install.packages("RWeka")
install.packages("neural")
install.packages("dummies")
install.packages("neuralnet")
install.packages("MASS")
library(foreign)#lectura archivos .sav
library(caret)
library(e1071)
library(nnet)
library(RWeka)
library(neural)
library(dummies)
library(neuralnet)
library(MASS);
library(ggplot2)
modelo.nn <- neuralnet(frml,
data          = train,
hidden        = c(5,2), # ver Notas para detalle
threshold     = 0.05,   # ver Notas para detalle
algorithm     = "rprop+"
)
modelo.nn <- neuralnet(frml,
data          = train,
hidden        = c(5,2), # ver Notas para detalle
threshold     = 0.05,   # ver Notas para detalle
algorithm     = "rprop+"
)
nms  <- names(train)
frml <- as.formula(paste("AGR_ALFAB ~", paste(nms[!nms %in% "AGR_ALFAB"], collapse = " + ")))
modelo.nn <- neuralnet(frml,
data          = train,
hidden        = c(5,2), # ver Notas para detalle
threshold     = 0.05,   # ver Notas para detalle
algorithm     = "rprop+"
)
modelo.nn <- neuralnet(frml,
data          = train,
hidden        = c(5,2), # ver Notas para detalle
threshold     = 0.05,   # ver Notas para detalle
algorithm     = "rprop+"
)
#Regresion simple
modelo_simple <- lm(data = datosP, formula = AGR_ALFAB ~ .)
modelo_simple
names(modelo_simple)
summary(modelo_simple)
plot(modelo_simple)
plot(x = lstat, y = medv, main = "medv vs lstat", pch = 20, col = "grey30")
modelo_simple
plot(x = AGR_ALFAB, main = "medv vs lstat", pch = 20, col = "grey30")
View(Boston)
datosP)
attach(datosP)
plot(x = AGR_ALFAB, main = "AGR_ALFAB vs . ", pch = 20, col = "grey30")
plot(x = AGR_ALFAB, main = "AGR_ALFAB vs . ", pch = 20, col = "grey30")
abline(modelo_simple, lwd = 3, col = "red")
#Regresion simple
modelo_simple <- lm(data = datosP, formula = AGR_TRABAJA ~ .)
attach(datosP)
plot(x = AGR_TRABAJA, main = "AGR_TRABAJA vs . ", pch = 20, col = "grey30")
abline(modelo_simple, lwd = 3, col = "red")
library(foreign)#lectura archivos .sav
library(ggplot2)
library(dplyr)
library(plyr)
library(cluster)
library(fpc)
library(mclust)
library(e1071)#para cmeans
library(factoextra)
datos = merge(newdata16,newdata17, all.x=T)
summary(datosP)
# ----------------------------------------------------------------------------------------------------------------------------------------------------------------
# Summary
# ---------------------
summary(dataset16)
myvars16 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
newdata16 <- select(dataset16, one_of(myvars16))
newdata16
myvars17 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
newdata17 <- select(dataset17, one_of(myvars17))
newdata17
datosP = merge(newdata16,newdata17, all.x=TRUE)
summary(datosP)
myvars16 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
newdata16 <- select(dataset16, one_of(myvars16))
newdata16
summary(newdata16)
#KIUVOLEWEY
myvars16 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
newdata16 <- select(dataset16, one_of(myvars16))
newdata16
summary(newdata16)
myva16 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
ndata16 <- select(dataset16, one_of(myva16))
library(foreign)#lectura archivos .sav
library(ggplot2)
library(dplyr)
library(plyr)
library(cluster)
library(fpc)
library(mclust)
library(e1071)#para cmeans
library(factoextra)
myva16 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
ndata16 <- select(dataset16, one_of(myva16))
#KIUVOLEWEY
myva16 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
ndata16 <- select(dataset16, one_of(myva16))
myva17 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
ndata17 <- select(dataset17, one_of(myva17))
datP = merge(ndata16,ndata17, all.x=TRUE)
summary(datP)
View(dataset16)
View(dataset17)
View(dataset16)
newDataAGR16 <- dataset16[,c("AGR_SEXO", "AGR_EDAD", "AGR_ESCOLARIDAD", "AGR_ALFAB", "AGR_EST_CIV", "AGR_GURPET", "AGR_TRABAJA")]
newDataAGR17 <- dataset17[,c("AGR_SEXO", "AGR_EDAD", "AGR_ESCOLARIDAD", "AGR_ALFAB", "AGR_EST_CIV", "AGR_GURPET", "AGR_TRABAJA")]
newDataVIC16 <- dataset16[,c("VIC_SEXO", "VIC_EDAD", "VIC_ESCOLARIDAD", "VIC_ALFAB", "VIC_EST_CIV", "VIC_GRUPET", "VIC_TRABAJA")]
newDataVIC17 <- dataset17[,c("VIC_SEXO", "VIC_EDAD", "VIC_ESCOLARIDAD", "VIC_ALFAB", "VIC_EST_CIV", "VIC_GRUPET", "VIC_TRABAJA")]
colnames(newDataAGR16) <- c('SEXO', 'EDAD', 'ESCOLARIDAD', 'ALFABETIZACION', 'ESTADO_CIVIL', 'GRUPET', 'TRABAJA')
colnames(newDataAGR17) <- c('SEXO', 'EDAD', 'ESCOLARIDAD', 'ALFABETIZACION', 'ESTADO_CIVIL', 'GRUPET', 'TRABAJA')
colnames(newDataVIC16) <- c('SEXO', 'EDAD', 'ESCOLARIDAD', 'ALFABETIZACION', 'ESTADO_CIVIL', 'GRUPET', 'TRABAJA')
colnames(newDataVIC17) <- c('SEXO', 'EDAD', 'ESCOLARIDAD', 'ALFABETIZACION', 'ESTADO_CIVIL', 'GRUPET', 'TRABAJA')
newDataAGR16 <- na.omit(newDataAGR16)
newDataAGR17 <- na.omit(newDataAGR17)
newDataVIC16 <- na.omit(newDataAGR16)
newDataVIC17 <- na.omit(newDataAGR17)
newDataAGR16$AGROVIC <- '1'
newDataAGR17$AGROVIC <- '1'
newDataVIC16$AGROVIC <- '2'
newDataVIC17$AGROVIC <- '2'
dataAGR <- rbind(newDataAGR16, newDataAGR17, all.x = T)
str(dataAGR)
dataVIC <- rbind(newDataVIC16, newDataVIC17, all.x = T)
str(dataVIC)
allData <- rbind(dataVIC, dataAGR, all.x = T)
allData <- na.omit(allData)
str(newData16) # Tipos de variables de las columnas de la base de datos
allData$AGROVIC <- as.factor(allData$AGROVIC)
summary(allData)
View(allData)
porcentaje = 0.7
set.seed(123)
corte <- sample(nrow(allData), nrow(allData)*porcentaje)
train_data = allData[corte,]
test_data = allData[-corte,]
#M1
model_svm <- svm(AGROVIC ~ . , train_data)
library(caret)
library(e1071)
library(nnet)
library(RWeka)
library(neural)
library(dummies)
library(neuralnet)
library(MASS)
#M1
model_svm <- svm(AGROVIC ~ . , train_data)
model_svm
pred <- predict(model_svm, test_data[,1:ncol(test_data)])
confusionMatrix(as.factor(test_data$AGROVIC),pred)
#Plot the dataset
plot(train_data,pch=16)
#Linear regression
model <- lm(AGROVIC ~ ., train_data)
#Linear regression
model <- lm(AGROVIC ~ ., train_data)
#Plot the dataset
plot(train_data,pch=16)
#Plot the dataset
plot(train_data,pch=16)
#Linear regression
model <- lm(AGROVIC ~ ., train_data)
#Plot the model using abline
abline(model)
porcentaje = 0.7
set.seed(123)
corte <- sample(nrow(allData), nrow(allData)*porcentaje)
train_data = allData[corte,]
test_data = allData[-corte,]
#M1
model_svm <- svm(AGROVIC ~ . , train_data)
library(ggplot2)
library(dplyr)
library(plyr)
library(cluster)
library(fpc)
library(mclust)
library(e1071)#para cmeans
library(factoextra)
library(caret)
library(e1071)
library(rpart)
library(nnet)
library(RWeka)
library(neural)
library(dummies)
library(neuralnet)
library(MASS)
summary(allData)
porcentaje = 0.7
set.seed(123)
corte <- sample(nrow(allData), nrow(allData)*porcentaje)
train_data = allData[corte,]
test_data = allData[-corte,]
#M1
model_svm <- svm(AGROVIC ~ . , train_data)
pred <- predict(model_svm, test_data[,1:ncol(test_data)])
confusionMatrix(as.factor(test_data$AGROVIC),pred)
summary(train_data)
newDataAGR16 <- dataset16[,c("AGR_DEDICA", "AGR_TRABAJA")]
newDataAGR17 <- dataset17[,c("AGR_DEDICA", "AGR_TRABAJA")]
newDataVIC16 <- dataset16[,c("VIC_DEDICA", "VIC_TRABAJA")]
newDataVIC16 <- dataset16[,c("VIC_DEDICA", "VIC_TRABAJA")]
newDataVIC17 <- dataset17[,c("VIC_DEDICA", "VIC_TRABAJA")]
colnames(newDataAGR16) <- c('DEDICA', 'TRABAJA')
colnames(newDataAGR16) <- c('DEDICA', 'TRABAJA')
colnames(newDataAGR17) <- c('DEDICA', 'TRABAJA')
colnames(newDataVIC16) <- c('DEDICA', 'TRABAJA')
colnames(newDataVIC17) <- c('DEDICA', 'TRABAJA')
newDataAGR16 <- na.omit(newDataAGR16)
newDataAGR17 <- na.omit(newDataAGR17)
newDataVIC16 <- na.omit(newDataAGR16)
newDataVIC17 <- na.omit(newDataAGR17)
newDataAGR16$AGROVIC <- '1'
newDataAGR17$AGROVIC <- '1'
newDataVIC16$AGROVIC <- '2'
newDataVIC17$AGROVIC <- '2'
dataAGR <- rbind(newDataAGR16, newDataAGR17, all.x = T)
str(dataAGR)
dataVIC <- rbind(newDataVIC16, newDataVIC17, all.x = T)
str(dataVIC)
allData <- rbind(dataVIC, dataAGR, all.x = T)
allData <- na.omit(allData)
str(newData16) # Tipos de variables de las columnas de la base de datos
str(newData17)
str(allData)
allData$AGROVIC <- as.factor(allData$AGROVIC)
summary(allData)
porcentaje = 0.7
set.seed(123)
corte <- sample(nrow(allData), nrow(allData)*porcentaje)
train_data = allData[corte,]
test_data = allData[-corte,]
summary(train_data)
#M1
model_svm <- svm(AGROVIC ~ . , train_data)
model_svm
pred <- predict(model_svm, test_data[,1:ncol(test_data)])
confusionMatrix(as.factor(test_data$AGROVIC),pred)
setwd("C:/Users/DELL/Documents/UVG/VIII_Semestre/Data Science/DSLaboratorio3")
# --------------------
# Lectura de los datos
# --------------------
datos <- read.csv("datoslmp")
# --------------------
# Lectura de los datos
# --------------------
datos <- read.csv("datosImp")
# --------------------
# Lectura de los datos
# --------------------
datos <- read.csv("datosImp")
# --------------------
# Lectura de los datos
# --------------------
datos <- read.csv("datosLmp")
# --------------------
# Lectura de los datos
# --------------------
datos <- read.csv("datosLmp.csv")
# --------------------
# Lectura de los datos
# --------------------
datos <- read.csv("datosImp.csv")
summary(datos)
setwd("C:/Users/DELL/Documents/UVG/VIII_Semestre/Data Science/DSLaboratorio3")
# --------------------
# Lectura de los datos
# --------------------
datos <- read.csv("datosImp.csv")
summary(datos)
View(datos)
library(forecast)
library(tseries)
install.packages("forecast")
summary(datos)
install.packages("tseries")
library(ggfortify)
install.packages("ggfortify")
summary(datos)
library(tseries)
library(forecast)
library(ggfortify)
#Transformamos los datos en una serie temporal
datos2ts<-ts(co2$Diesel, start = c(2001,2019))
#Transformamos los datos en una serie temporal
datos2ts<-ts(datos$Diesel, start = c(2001,2019))
print(co2ts)
print(datos2ts)
#Trazamos la serie de tiempo datos2ts
autoplot(datos2ts, ts.colour = "blue", ts.linetype = "dashed")
datos2ts
#Verifiacion de varianza
autoplot(acf(datos2ts, plot = FALSE))
#Verifiacion de varianza
autoplot(acf(datos2ts, plot = FALSE))
#Trazamos la serie de tiempo datos2ts
autoplot(datos2ts, ts.colour = "blue", ts.linetype = "dashed")
#Verifiacion de varianza
autoplot(acf(datos2ts, plot = FALSE))
autoplot(stl(datos2ts, s.window = "periodic"), ts.colour = "blue")
#Transformamos los datos en una serie temporal
datos2ts<-ts(datos$Diesel, start = c(2001,2019), frequency = 12)
print(datos2ts)
#Trazamos la serie de tiempo datos2ts
autoplot(datos2ts, ts.colour = "blue", ts.linetype = "dashed")
#Verifiacion de varianza
autoplot(acf(datos2ts, na.action = na.pass, plot = FALSE))
autoplot(stl(datos2ts, s.window = "periodic"), ts.colour = "blue", na.action = na.pass)
autoplot(stl(datos2ts, na.action = na.pass, s.window = "periodic"), ts.colour = "blue")
#Trazamos la serie de tiempo datos2ts
autoplot(datos2ts, ts.colour = "blue", ts.linetype = "dashed", title = "Diesel behavior")
class(datos)
#Saber cuando empieza la serie y cuando termina
start(datos)
# --------------------
# Lectura de los datos
# --------------------
datos <- read.csv("datosImp.csv")
summary(datos)
class(datos)
#Saber cuando empieza la serie y cuando termina
start(datos)
library(fUnitRoots)
install.packages("fUnitRoots")
library(fUnitRoots)
# --------------------
# Lectura de los datos
# --------------------
datos <- read.csv("datosImp.csv")
class(datos)
#Saber cuando empieza la serie y cuando termina
start(datos)
#Saber cuando empieza la serie y cuando termina
start(datos$Diesel)
#Saber cuando empieza la serie y cuando termina
start(datos$Diesel)
end(datos$Diesel)
#Saber la frecuencia de la serie
frequency(datos$Diesel)
#Transformamos los datos en una serie temporal
datos2ts<-ts(datos$Diesel, start = c(2001,2019), frequency = 12)
library(forecast)
library(tseries)
library(fUnitRoots)
library(ggfortify)
data("AirPassengers")
class(AirPassengers)
#Saber cuando empieza la serie y cuando termina
start(AirPassengers)
print(data)
#Saber cuando empieza la serie y cuando termina
start(AirPassengers)
end(AirPassengers)
#Saber la frecuencia de la serie
frequency(AirPassengers)
#Ver el grÃ¡fico de la serie
plot(AirPassengers)
abline(reg=lm(AirPassengers~time(AirPassengers)), col=c("red"))
library(forecast)
library(tseries)
library(ggfortify)
setwd("C:/Users/DELL/Documents/UVG/VIII_Semestre/Data Science/DSLaboratorio3")
# --------------------
# Lectura de los datos
# --------------------
datos <- read.csv("datosImp.csv")
summary(datos)
class(datos)
#Transformamos los datos en una serie temporal
datos2ts<-ts(datos$Diesel, start = c(2001,2019), frequency = 12)
#Trazamos la serie de tiempo datos2ts
autoplot(datos2ts, ts.colour = "blue", ts.linetype = "dashed", title = "Diesel behavior")
#Trazamos la serie de tiempo datos2ts
autoplot(datos2ts, ts.colour = "blue", ts.linetype = "dashed", xlab = "Time", ylab = "Diesel",
title = "Diesel behavior")
#Transformamos los datos en una serie temporal
datos2ts<-ts(datos$Diesel, start = c(2001,1), frequency = 12)
print(datos2ts)
#Trazamos la serie de tiempo datos2ts
autoplot(datos2ts, ts.colour = "blue", ts.linetype = "dashed", xlab = "Time", ylab = "Diesel",
title = "Diesel behavior")
#Verifiacion de varianza
autoplot(acf(datos2ts,  plot = FALSE))
na.action = na.pass,
#Verifiacion de varianza
autoplot(acf(datos2ts, na.action = na.pass, plot = FALSE))
autoplot(stl(datos2ts, na.action = na.pass, s.window = "periodic"), ts.colour = "blue")
autoplot(stl(datos2ts, s.window = "periodic"), ts.colour = "blue")
# --------------------
# Lectura de los datos
# --------------------
datos <- read.csv("datosImp.csv")
datos <- na.omit
#Transformamos los datos en una serie temporal
datos2ts<-ts(datos$Diesel, start = c(2001,1), frequency = 12)
class(datos)
#Transformamos los datos en una serie temporal
datos2ts<-ts(datos$Diesel, start = c(2001,1), frequency = 12)
# --------------------
# Lectura de los datos
# --------------------
datos <- read.csv("datosImp.csv")
#Transformamos los datos en una serie temporal
datos2ts<-ts(datos$Diesel, start = c(2001,1), frequency = 12)
autoplot(stl(datos2ts, s.window = "periodic"), ts.colour = "blue")
autoplot(stl(datos2ts, s.window = "convolution"), ts.colour = "blue")
autoplot(stl(datos2ts, s.window = "periodic"), na.action = na.pass, ts.colour = "blue")
autoplot(stl(datos2ts, na.action = na.pass, s.window = "periodic"), na.action = na.pass, ts.colour = "blue")
#MODELO ARIMA
ndiffs(datos2ts)
nsdiffs(datos2ts)
plot(decompose(datos2ts))
diff.datos2ts<-autoplot(diff(datos2ts), ts.linetype = "dashed", ts.colour = "darkmagenta")
diff.datos2ts
diff.datos2ts<-autoplot(diff(datos2ts), ts.linetype = "dashed", ts.colour = "darkmagenta")
diff.datos2ts
# --------------------
# Lectura de los datos
# --------------------
datos <- read.csv("datosImp.csv")
#Transformamos los datos en una serie temporal
datos2ts<-ts(datos$Diesel, start = c(2001,1), frequency = 12)
diff.datos2ts<-autoplot(diff(datos2ts), ts.linetype = "dashed", ts.colour = "darkmagenta")
diff.datos2ts
